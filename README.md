# ğŸ§  NVIDIA NIM PDF Chatbot

Chat with your **own PDF documents** using **NVIDIA NIM**, **LangChain**, **FAISS**, and **Streamlit**.

This app builds a local vector store over your PDFs and uses the
`meta/llama-3.3-70b-instruct` model served via **NVIDIA Inference Microservices (NIM)**
to answer questions grounded strictly in your documents.

> **Tech focus:** Retrieval-Augmented Generation (RAG) with NVIDIA NIM.

---

## ğŸš€ Demo

![Demo](demo/main_page.png)


---

## âœ¨ Features

- ğŸ”— RAG over local PDFs using FAISS and NVIDIAEmbeddings
- ğŸ§  NVIDIA NIM LLM (meta/llama-3.3-70b-instruct) for high-quality answers
- ğŸ§© Chunking & retrieval with RecursiveCharacterTextSplitter and LangChain retriever
- ğŸ“ Source transparency â€“ view the exact chunks used to answer each question
- âš™ï¸ Configurable retrieval (top-k slider for number of chunks)
- ğŸ“Š Live metrics â€“ number of PDFs, chunks, and last response time
- ğŸ–¥ï¸ Clean Streamlit UI ready for local or cloud deployment

  ---

## ğŸ§± Architecture
```mermaid
flowchart TD
    A["ğŸ“‚ PDF Folder (./us_census)"] --> B["ğŸ“„ PyPDFDirectoryLoader"]
    B --> C["ğŸ§© RecursiveCharacterTextSplitter<br/>chunk_size=700, overlap=50"]
    C --> D["ğŸ”¢ NVIDIAEmbeddings (NIM)"]
    D --> E["ğŸ“Š FAISS Vector Store"]

    F["ğŸ’¬ User Question"] --> G["ğŸ” Retriever (top-k)"]
    G --> H["ğŸ“š Context + Question"]
    H --> I["ğŸ¤– ChatNVIDIA (meta/llama-3.3-70b-instruct)"]
    I --> J["ğŸ“ Answer in Streamlit UI"]
    G --> K["ğŸ“ Source Chunks in Expander"]
```

---

## ğŸ§° Tech Stack

- Frontend / App: Streamlit
- Model Serving: NVIDIA NIM (meta/llama-3.3-70b-instruct)
- RAG Framework: LangChain (community + core + text splitters)
- Vector Store: FAISS (CPU)
- Document Loader: PyPDFDirectoryLoader
- Config: python-dotenv for managing NVIDIA_API_KEY


---

## ğŸ“‚ Project Structure
```bash
NVIDIA-NIM-PDF-Chatbot/
â”œâ”€ us_census/               # Sample PDFs (add your documents here)
â”œâ”€ finalapp.py              # Main Streamlit application
â”œâ”€ requirements.txt         # Python dependencies
â”œâ”€ .env.example             # Template for NVIDIA API key
â””â”€ README.md
```

---

## âš™ï¸ Setup & Installation

### 1ï¸âƒ£ Clone the repository
```
git clone https://github.com/<your-username>/NVIDIA-NIM-PDF-Chatbot.git
cd NVIDIA-NIM-PDF-Chatbot
```

### 2ï¸âƒ£ Create and activate a virtual environment (optional but recommended)
```
python -m venv venv
source venv/bin/activate      # macOS / Linux
# venv\Scripts\activate       # Windows
```

### 3ï¸âƒ£ Install dependencies
```
pip install -r requirements.txt
```

### 4ï¸âƒ£ Configure NVIDIA NIM API key

Create a .env file in the project root:
```
NVIDIA_API_KEY=your_nim_api_key_here
```

You can get this key from the NVIDIA NIM / AI Foundation Models console.



  
